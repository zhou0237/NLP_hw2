{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNLI.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "0CMtCvHrhGlW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os.path import exists\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MlJfzG_shNym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pickle as pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NxdOE6wqhmRp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_preprocess(path, size):\n",
        "    \n",
        "    premise=[]\n",
        "    hypo = []\n",
        "    label =[]\n",
        "    genre=[]\n",
        "    with open(path) as files:\n",
        "        file = csv.reader(files, delimiter='\\t')\n",
        "        for row in file:\n",
        "            if row != ['sentence1', 'sentence2', 'label', 'genre']:\n",
        "                premise.append(row[0].split())\n",
        "                hypo.append(row[1].split())\n",
        "                if row[2] == 'contradiction':\n",
        "                    label.append(0.0)\n",
        "                elif row[2]=='entailment':\n",
        "                    label.append(1.0)\n",
        "                elif row[2]=='neutral': \n",
        "                    label.append(2.0)\n",
        "                else:\n",
        "                    print('Error Label')\n",
        "                genre.append(row[3])    \n",
        "    return premise, hypo, label, genre "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMw13UDNhoIt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s1_train, s2_train, y_train,gen_train = data_preprocess('/content/drive/hw2_data/mnli_train.tsv', 100000)\n",
        "\n",
        "s1_val, s2_val, y_val, gen_val = data_preprocess('/content/drive/hw2_data/mnli_val.tsv', 1000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOheuiwQmih9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2957f00-62ec-491e-efbc-37adf1bfa6fc"
      },
      "cell_type": "code",
      "source": [
        "unique_gen = set(gen_train)\n",
        "unique_gen"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fiction', 'government', 'slate', 'telephone', 'travel'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "o1gzns5RmpcN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "def load_vectors(fname,size):\n",
        "    PAD_IDX = 0\n",
        "    UNK_IDX = 1\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = np.zeros((size+2, 300))\n",
        "    \n",
        "    token2id = {'<pad>':PAD_IDX, '<unk>':UNK_IDX}\n",
        "    id2token = {PAD_IDX:'<pad>', UNK_IDX:'<unk>'}\n",
        "    np.random.seed(1)\n",
        "    data[UNK_IDX] = np.random.rand(300)\n",
        "    i =0\n",
        "    for line in fin:\n",
        "        i +=1\n",
        "        if i>size:\n",
        "            break\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[i+1, :] = np.asarray(tokens[1:])\n",
        "        token2id[tokens[0]] = i+1\n",
        "        id2token[i+1] = tokens[0]\n",
        "\n",
        "    return data, token2id, id2token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QuORSRCz0Rbf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dictionary_size= 100000\n",
        "PAD_IDX = 0\n",
        "UNK_IDX = 1\n",
        "vector_load, token2id, id2token= load_vectors('/content/drive/hw2_data/wiki-news-300d-1M.vec',dictionary_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ITqoERk_0ZtP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "s1_val_gove = []\n",
        "s2_val_gove =[]\n",
        "y_val_gove = []\n",
        "\n",
        "\n",
        "s1_val_tele = []\n",
        "s2_val_tele =[]\n",
        "y_val_tele = []\n",
        "\n",
        "s1_val_slate = []\n",
        "s2_val_slate=[]\n",
        "y_val_slate = []\n",
        "\n",
        "s1_val_trave = []\n",
        "s2_val_trave =[]\n",
        "y_val_trave = []\n",
        "\n",
        "\n",
        "s1_val_fict = []\n",
        "s2_val_fict =[]\n",
        "y_val_fict = []\n",
        "\n",
        "for ind, val in enumerate(s1_val):\n",
        "  if gen_val[ind]=='fiction':    \n",
        "    s1_val_fict.append(s1_val[ind])\n",
        "    s2_val_fict.append(s2_val[ind])\n",
        "    y_val_fict.append(y_val[ind])\n",
        "  elif gen_val[ind]=='government': \n",
        "    s1_val_gove.append(s1_val[ind])\n",
        "    s2_val_gove.append(s2_val[ind])\n",
        "    y_val_gove.append(y_val[ind])\n",
        "  elif gen_val[ind]=='telephone': \n",
        "    s1_val_tele.append(s1_val[ind])\n",
        "    s2_val_tele.append(s2_val[ind])\n",
        "    y_val_tele.append(y_val[ind])    \n",
        "\n",
        "  elif gen_val[ind]=='slate': \n",
        "    s1_val_slate.append(s1_val[ind])\n",
        "    s2_val_slate.append(s2_val[ind])\n",
        "    y_val_slate.append(y_val[ind])\n",
        "  else:\n",
        "    s1_val_trave.append(s1_val[ind])\n",
        "    s2_val_trave.append(s2_val[ind])\n",
        "    y_val_trave.append(y_val[ind])   \n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4gWfEQk42SuH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NewsGroupDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
        "    Note that this class inherits torch.utils.data.Dataset\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, data_list1,data_list2, target_list):\n",
        "        \"\"\"\n",
        "        @param data_list: list of newsgroup tokens \n",
        "        @param target_list: list of newsgroup targets \n",
        "\n",
        "        \"\"\"\n",
        "        self.data_list1 = data_list1\n",
        "        self.data_list2 = data_list2\n",
        "        self.target_list = target_list\n",
        "        assert (len(self.data_list1) == len(self.target_list))\n",
        "        assert (len(self.data_list2) == len(self.target_list))\n",
        "    def __len__(self):\n",
        "        return len(self.data_list1)\n",
        "        \n",
        "    def __getitem__(self, key):\n",
        "        \"\"\"\n",
        "        Triggered when you call dataset[i]\n",
        "        \"\"\"\n",
        "        \n",
        "        token_idx1 = self.data_list1[key][:MAX_SENTENCE_LENGTH_1]\n",
        "        token_idx2 = self.data_list2[key][:MAX_SENTENCE_LENGTH_2]\n",
        "        label = self.target_list[key]\n",
        "        return [token_idx1, len(token_idx1), token_idx2, len(token_idx2), label]\n",
        "              \n",
        "\n",
        "def newsgroup_collate_func(batch):\n",
        "    \"\"\"\n",
        "    Customized function for DataLoader that dynamically pads the batch so that all \n",
        "    data have the same length\n",
        "    \"\"\"\n",
        "    data_list1 = []\n",
        "    data_list2 = []\n",
        "    label_list = []\n",
        "    length_list1 = []\n",
        "    length_list2 = []\n",
        "\n",
        "    \n",
        "    for datum in batch:\n",
        "        label_list.append(datum[4])\n",
        "        length_list1.append(datum[1])\n",
        "        length_list2.append(datum[3])\n",
        "\n",
        "    # padding\n",
        "    for datum in batch:\n",
        "        padded_vec1 = np.pad(np.array(datum[0]), \n",
        "                                pad_width=((0,MAX_SENTENCE_LENGTH_1-datum[1])), \n",
        "                                mode=\"constant\", constant_values=0)\n",
        "        data_list1.append(padded_vec1)        \n",
        "        \n",
        "        \n",
        "        padded_vec2 = np.pad(np.array(datum[2]), \n",
        "                                pad_width=((0,MAX_SENTENCE_LENGTH_2-datum[3])), \n",
        "                                mode=\"constant\", constant_values=0)\n",
        "\n",
        "        data_list2.append(padded_vec2)\n",
        "    \n",
        "    return [torch.from_numpy(np.array(data_list1)), torch.LongTensor(length_list1), \n",
        "            torch.from_numpy(np.array(data_list2)), torch.LongTensor(length_list2),torch.LongTensor(label_list)]\n",
        "  \n",
        "BATCH_SIZE = 32\n",
        "train_dataset = NewsGroupDataset(s1_train_indices, s2_train_indices, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=newsgroup_collate_func,\n",
        "                                           shuffle=True)\n",
        "\n",
        "val_dataset = NewsGroupDataset(s1_val_indices, s2_val_indices, y_val)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=newsgroup_collate_func,\n",
        "                                           shuffle=True)  \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "csaRiMZk2SxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "730b86e1-5196-4fed-fd99-9365574c3857"
      },
      "cell_type": "code",
      "source": [
        "model_rnn = torch.load('RNN_model4 .pth')\n",
        "model_cnn = torch.load('CNN_model3.pth')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "ZK_Sk0Kx2Szs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def token2index_dataset(tokens_data):\n",
        "    indices_data = []\n",
        "    for tokens in tokens_data:\n",
        "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
        "        indices_data.append(index_list)\n",
        "    return indices_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SaLmNrYE2S4U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s1_val_gove_indices = token2index_dataset(s1_val_gove)\n",
        "s2_val_gove_indices = token2index_dataset(s2_val_gove)\n",
        "\n",
        "s1_val_tele_indices = token2index_dataset(s1_val_tele)\n",
        "s2_val_tele_indices = token2index_dataset(s2_val_tele)\n",
        "\n",
        "\n",
        "\n",
        "s1_val_trave_indices = token2index_dataset(s1_val_trave)\n",
        "s2_val_trave_indices = token2index_dataset(s2_val_trave)\n",
        "\n",
        "s1_val_fict_indices = token2index_dataset(s1_val_fict)\n",
        "s2_val_fict_indices = token2index_dataset(s2_val_fict)\n",
        "\n",
        "s1_val_slate_indices = token2index_dataset(s1_val_slate)\n",
        "s2_val_slate_indices = token2index_dataset(s2_val_slate)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VWmXY-7v2S61",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_model(loader, model):\n",
        "    model.eval()\n",
        "    cor = 0\n",
        "    cnt = 0\n",
        "\n",
        "\n",
        "    for s1, s1_l,  s2, s2_1, labels in loader:\n",
        "        s1_batch1, batch1_1, s2_batch2, batch2_1, label_batch = s1, s1_l, s2, s2_1, labels\n",
        "        \n",
        "        \n",
        "        outputs = F.softmax(model(s1_batch1, batch1_1, s2_batch2, batch2_1), dim=1)\n",
        "        predict = outputs.max(1, keepdim=True)[1]\n",
        "\n",
        "        cnt += labels.size(0)\n",
        "        cor += predicted.eq(labels.view_as(predict)).sum().item()\n",
        "        accu = cor / cnt * 100\n",
        "        \n",
        "        \n",
        "    return (accu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3s86dqrW5U84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10b8070f-0173-4dc1-eb5a-42e1383e3bcf"
      },
      "cell_type": "code",
      "source": [
        "val_dataset_gove = SNLIDataset(s1_val_gove_indices, s2_val_gove_indices, y_val_gove)\n",
        "val_loader_gove = torch.utils.data.DataLoader(dataset=val_dataset_gove, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=SNLI_collate_func,\n",
        "                                           shuffle=False)\n",
        "\n",
        "print(\"CNN Val Acuu: {} ; RNN Val Acuu:{} \".format(test_model(val_loader_fict, model_cnn),test_model(val_loader_fict, model_rnn))\n",
        "      "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN Val Acuu: 41.1 ; RNN Val Acuu: 44.2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9ABAJ8mA5VJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18c3413c-4e09-4284-d03b-1c09965e413c"
      },
      "cell_type": "code",
      "source": [
        "val_dataset_trave = SNLIDataset(s1_val_travee_indices, s2_val_trave_indices, y_val_trave)\n",
        "val_loader_trave = torch.utils.data.DataLoader(dataset=val_dataset_trave, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=SNLI_collate_func,\n",
        "                                           shuffle=False)\n",
        "\n",
        "print(\"CNN Val Acuu:{} ; RNN Val Acuu: {} \".format(test_model(val_loader_fict, model_cnn),test_model(val_loader_fict, model_rnn))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN Val Acuu: 40.6 ; RNN Val Acuu: 42.3 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ESIeEDow5VUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "771ace89-ec77-4499-d85f-003ea14c9471"
      },
      "cell_type": "code",
      "source": [
        "val_dataset_tele = SNLIDataset(s1_val_tele_indices, s2_val_tele_indices, y_val_tele )\n",
        "val_loader_tele = torch.utils.data.DataLoader(dataset=val_dataset_tele, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=SNLI_collate_func,\n",
        "                                           shuffle=False)\n",
        "\n",
        "print(\"CNN Val Acuu: {} ; RNN Val Acuu: {} \".format(test_model(val_loader_fict, model_cnn),test_model(val_loader_fict, model_rnn))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN Val Acuu: 40.3 ; RNN Val Acuu: 45.3 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nNy4KD9t5Vk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2c4d798-6ebf-427b-ff91-c3cc770ec65f"
      },
      "cell_type": "code",
      "source": [
        "val_dataset_slate = SNLIDataset(s1_val_slate_indices, s2_val_slate_indices, y_slate_gove)\n",
        "val_loader_slate = torch.utils.data.DataLoader(dataset=val_dataset_slate, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=SNLI_collate_func,\n",
        "                                           shuffle=False)\n",
        "\n",
        "print(\"CNN Val Acuu: {} ; RNN Val Acuu: {} \".format(test_model(val_loader_fict, model_cnn),test_model(val_loader_fict, model_rnn))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN Val Acuu: 42.2 ; RNN Val Acuu: 46.2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r47ma9un5V4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da264a2b-3f1f-4164-9922-f4a3d091326e"
      },
      "cell_type": "code",
      "source": [
        "val_dataset_fict = SNLIDataset(s1_val_fict_indices, s2_val_fict_indices, y_val_fict)\n",
        "val_loader_gove = torch.utils.data.DataLoader(dataset=val_dataset_fict, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=SNLI_collate_func,\n",
        "                                           shuffle=False)\n",
        "\n",
        "print(\"CNN Val Acuu: {} ; RNN Val Acuu: {} \".format(test_model(val_loader_fict, model_cnn),test_model(val_loader_fict, model_rnn))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN Val Acuu: 42.1 ; RNN Val Acuu: 45.2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fV83OxLu5WD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}